{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Political Alignment Analysis in 140 Characters \n",
    "#### CX 4240, Spring 2019 \n",
    "#### Jessica Buzzelli, Jarad Hosking, Aakanksha Patil "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I: Problem\n",
    "\n",
    "Twitter is a social media platform where users' status updates (tweets) can have the ability to impact how their followers percieve events, [especially in the realm of politics](https://www.nytimes.com/2019/04/11/us/politics/on-politics-twitter-democrats.html). In this project, we wanted to see how accuractely we could identify users' political affiliations, with the goal of making a model that could be applied to identify like-minded public figures to a given user.\n",
    "\n",
    "Especially with [Twitter's ongoing decline in monthly users](https://www.bloomberg.com/news/articles/2018-07-27/twitter-projects-users-to-decline-profit-short-of-estimates), we hypothesize that such a tool could be used to further establish the site as a more specialized hub for political news and debate and, in turn, drive platform-unique content and reinvigorate overall site traffic. Another high potential use case could involve matching individuals with similarly-aligned local politicians in order to inspire more people to participate in non-federal elections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II: Approach\n",
    "\n",
    "In order to meaningfully visualize our model projections, we chose to use a Nolan Chart as our frame of reference. We extracted ground-truth information on training users (politicians) from [OnTheIssues.org](), and solved for unknown scores of our test users. \n",
    "\n",
    "An example of a Nolan Chart from our source mapping Donald Trump to a point at (.8,.2):\n",
    "\n",
    "<img src=\"report_imgs/donald_trump.gif\" width=\"400\"/>\n",
    "\n",
    "Our problem lies somewhere between a clustering and a classification problem:\n",
    "1. We want to know which users are most similar to a test user, but\n",
    "1. Our classification \"labels\" are non-discrete, and\n",
    "1. We wanted to project onto a space where we can bring prior knowledge on political parties, schools of thought into our interpretation of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III: Dataset\n",
    "\n",
    "Since Twitter frowns upon (but allows) its data being used to identify users based on federally protected classes such as political alignment, we have limited our test set of data to users whose public presences are based around their political commentary -- we refer to them collectively in this project as pundits.\n",
    "\n",
    "Using a [Twitter API Python client](http://www.tweepy.org/) and an [SQLite](https://www.sqlite.org/index.html) database, we were able to pull tweets from a collection of politicians and pundits with the following characteristics.\n",
    "\n",
    "__NOTE:__ We were not able to obtain as many training users (politicians) as ideal due to the lack of politicians with Twitter accounts active enough to have more than 2,000 tweets since the 2016 presidential election (a limit we saw necessary in case of changes in political affiliation over time). We had no problem finding active pundits on the platform, but restrained our test numbers to scale well with our set of politicians. \n",
    "\n",
    "Nolan Chart breakdown of users in our dataset:\n",
    "\n",
    "<img src=\"report_imgs/newflows.png\" width=\"700\"/>\n",
    "\n",
    "__NOTE:__ We were unable to find any good examples of populists for our dataset, and therefore would ideally use a different visualization convention if unbiased ground-truth data were similiarly available.\n",
    "\n",
    "Before composing our feature matrix from the tweets in our database, we cleaned each tweet as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['twitter', 'follow', 'trend', 'stop', 'read', 'favorit', 'politician']\n"
     ]
    }
   ],
   "source": [
    "from preproccess_tweets import Preprocessor\n",
    "\n",
    "test_tweet = \"\"\"RT @user: I really like using Twitter to follow #trends;\n",
    "                I can't stop reading about my favorite politicians! \"\"\"\n",
    "\n",
    "print(Preprocessor().preprocess(test_tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After, we used [Term Frequency x Inverse Document Frequency (TF-IDF) scores](https://nlp.stanford.edu/IR-book/html/htmledition/tf-idf-weighting-1.html) trained on the politicians' combined corpus to build a feature matrix. \n",
    "\n",
    "This worked by 1) excluding words not used by the polticians' accounts and to 2) minimizing the weight of words that were rarely used by multiple politicans. \n",
    "\n",
    "Our feature matricies had __378,013 training records__, __67,088 testing records__, __65,376 unique features__ (same number of features in training and testing matricies), and looked something like this:\n",
    "\n",
    "<img src=\"report_imgs/vecs2.png\" width=\"550\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV: Results\n",
    "\n",
    "### Attempt 1: Linear Regression\n",
    "\n",
    "A [similiar problem](https://medium.com/linalgo/predict-political-bias-using-python-b8575eedef13) used logistic regression and clustering to predict the bias of newspaper headlines, but we used linear regression to get hard \"classifications\" of our training users' scores instead of clustering the data and reducing the dimensions down to a graphable output.\n",
    "\n",
    "Knowing that linear regressions vary much more as the number of features exceeds the number of data points, we applied Principal Component Analysis to bring our xtrain and xtest matricies down to __75 features__ (determined trialing with varying numbers of components). The improvement in results was significant:\n",
    "\n",
    "<img src=\"report_imgs/PCA.png\" width=\"1300\"/>\n",
    "\n",
    "The PCA model (the winner) had an average error of 24.0324 units of distance on the Nolan Chart (the difference of roughly one quadrant) with a standard deviation of 5 units. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model's pundit estimations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features (post-processing): 24972\n",
      "\n",
      "Regression results:\n",
      "                economic_score_estimate  social_score_estimate  \\\n",
      "author_handle                                                    \n",
      "PostOpinions                   0.603092               0.453282   \n",
      "ObsoleteDogma                  0.569767               0.565621   \n",
      "demsocialists                  0.271233               0.696731   \n",
      "JonathanLKrohn                 0.531447               0.430418   \n",
      "JoeNBC                         0.602881               0.440418   \n",
      "IngrahamAngle                  0.666145               0.275623   \n",
      "GlennBeck                      0.637169               0.390862   \n",
      "RedState                       0.731189               0.247807   \n",
      "Heritage                       0.795789               0.321089   \n",
      "MichelleMalkin                 0.708965               0.250840   \n",
      "KellyannePolls                 0.719816               0.392904   \n",
      "lizmair                        0.495508               0.479168   \n",
      "reason                         0.672513               0.425384   \n",
      "nprpolitics                    0.596184               0.394202   \n",
      "benshapiro                     0.684465               0.281209   \n",
      "juliaioffe                     0.591687               0.414527   \n",
      "KrangTNelson                   0.479557               0.426068   \n",
      "RealSaavedra                   0.795188               0.184838   \n",
      "TomiLahren                     0.672478               0.316506   \n",
      "RobDelaney                     0.200000               0.700000   \n",
      "\n",
      "               violated_user_bounds  \n",
      "author_handle                        \n",
      "PostOpinions                         \n",
      "ObsoleteDogma                        \n",
      "demsocialists                        \n",
      "JonathanLKrohn                       \n",
      "JoeNBC                               \n",
      "IngrahamAngle                        \n",
      "GlennBeck                            \n",
      "RedState                             \n",
      "Heritage                             \n",
      "MichelleMalkin                       \n",
      "KellyannePolls                       \n",
      "lizmair                              \n",
      "reason                               \n",
      "nprpolitics                          \n",
      "benshapiro                           \n",
      "juliaioffe                           \n",
      "KrangTNelson                   True  \n",
      "RealSaavedra                         \n",
      "TomiLahren                           \n",
      "RobDelaney                           \n"
     ]
    }
   ],
   "source": [
    "import linear_regression_model\n",
    "%matplotlib inline\n",
    "\n",
    "linear_regression_model.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Attempt 2: Feature Engineering via Latent Dirichlet Allocation and Sentiment Data\n",
    "\n",
    "Unlike [similar projects](https://medium.com/analytics-vidhya/twitter-sentiment-analysis-for-the-2019-election-8f7d52af1887) [using Twitter data for sentiment analysis](https://ieeexplore.ieee.org/document/6897213), we decided that a person's political affiliation is a combination of:\n",
    "\n",
    "1. The topics they care about (or in this case, tweet about), and\n",
    "1. Their sentiments (in this case, positive, negative, or neutral) towards those topics\n",
    "\n",
    "Using [Vader sentiment analyser](https://www.nltk.org/_modules/nltk/sentiment/vader.html), we proceded as follows:\n",
    "\n",
    "<img src=\"report_imgs/ldaflow.png\" width=\"1000\"/>\n",
    "\n",
    "Of course, we also ran a \"one vs. rest\" cross validation on an LDA model that did not use the sentiment approach detailed above:\n",
    "\n",
    "<img src=\"report_imgs/lda_comparisons2.png\" width=\"1500\"/>\n",
    "\n",
    "Cross validation results of the sentiment-enabled model had a higher mean error and estimation variance than the linear regression model, so we consider this approach a dead-end in its current state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V: Conclusion\n",
    "\n",
    "Considerations:\n",
    "* Sentiment data may have not been the most accurate given sarcasm, passive agressiveness aimed at other users, etc. \n",
    "\n",
    "* Very skeptical about the scalability of the regression model in Attempt 1 due to potential overfitting from our choice of number of components from PCA; could also have high variation due to tweets' small character limit making individual tweets poor reflections of a user's entire Twitter timeline\n",
    "\n",
    "* Topic-based models (Attempt 2) did not perform better when using feature reduction via Latent Semantic Indexing (LSI, or LDA with truncated SVD); had extremely high variances when set to fewer than 6 or more than 15 \"topics\"/components\n",
    "\n",
    "* Concerned about the possibility of users not tweeting as we would expect given a certain alignment; can only really counteract this by expanding our set of training users\n",
    "\n",
    "* Regression to project users onto the chart was tricky since we lacked enough datapoints at the extremes of the chart to be able to place users towards the corners -- especially in the populists' quadrant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of using the linear regression models to suggest users to follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linear_regression_model import returnRecommendations\n",
    "\n",
    "returnRecommendations('realDonaldTrump')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
